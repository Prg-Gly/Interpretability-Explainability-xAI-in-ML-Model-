# Interpretability-Explainability-xAI-in-ML-Model-
Application of Interpretability &amp; Explainability in ML models using Model-Agnostic Interpretable methods SHAP (SHapley Additive exPlanations) &amp; LIME (Local Interpretable Model-agnostic Explanations) to explain the prediction of risk flag for defaulters
Problem Statement : The data about historic customer behavior is given based on what was provided during loan application. Hence when they acquire new customers, they want to predict who is riskier and who is not.
Model fit & prediction done using classification-based algorithms such as Logistics Regression, Decision Tree, Random Forest & XG Boost.
3 Kaggle datasets were merged to create a comprehensive dataset. 
To expand the analysis horizon state census indicators such as GDP, population, per-capita income, poverty rate, unemployment rate were added to the dataset to explore the effect of demographic factors of the state in loan default prediction
Mix of Numerical & Categorical features : Income, Age, Experience, house-years; marital status, car ownership, house ownership, state, profession
Risk Flag of possible loan default is the outcome variable (1 – risk of default/ 0 – no risk of default)
